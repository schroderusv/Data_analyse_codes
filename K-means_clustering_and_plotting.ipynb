{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c445afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "import math\n",
    "from tslearn.barycenters import dtw_barycenter_averaging\n",
    "import base\n",
    "from scipy.stats import entropy\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import f_oneway\n",
    "import time\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e978a7",
   "metadata": {},
   "source": [
    "# Helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d490f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_values(column): #Values that needed to plot the diagram.\n",
    "    values, counts = np.unique(column, return_counts=True)\n",
    "    #need to convert to string to get only wanted values in the x-axis. Edit if you need int.\n",
    "    values_str = list(map(str, values))\n",
    "    return values_str, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc0cde5",
   "metadata": {},
   "source": [
    "# Merging the responses to app use data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d245de",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_data = pd.read_csv('APP_DATA.csv')\n",
    "\n",
    "question_data = pd.read_csv('QUESTION_DATA.csv')\n",
    "\n",
    "res = app_data.merge(question_data, how='inner', left_on=['uuid', 'PERIOD_END_DATE'], right_on=['uuid', 'date'])\n",
    "\n",
    "#res.to_csv('MERGED_DATA.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4856119d",
   "metadata": {},
   "source": [
    "# Data preprosessing for K-means (all categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a998c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting the tools-category as it does have data we don't need\n",
    "#Counting the total hourly app use of different users\n",
    "\n",
    "df = pd.read_csv('MERGED_DATA.csv')\n",
    "df = df.drop(['TOOLS'], axis=1)\n",
    "df['total'] = df.iloc[:, 3:41].sum(axis=1)\n",
    "df = df[['uuid', 'PERIOD_END_DATE', 'HOUR', 'total']]\n",
    "\n",
    "#Creating a temporary file\n",
    "#This file will have hours as columns\n",
    "\n",
    "df[\"index\"] = df[\"uuid\"] + ':' + df[\"PERIOD_END_DATE\"]\n",
    "df = df.drop(['uuid', 'PERIOD_END_DATE'], axis=1)\n",
    "\n",
    "\n",
    "df = df.pivot_table(values='total', index='index', columns='HOUR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f309b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the data prettier and more readable and filling NA-values\n",
    "\n",
    "df = pd.read_csv('TEMP_FILE.csv')\n",
    "df[['uuid', 'period_end_date']] = df['index'].str.split(':', 1, expand=True)\n",
    "df = df.drop(['index'], axis=1)\n",
    "cols = list(df.columns.values)\n",
    "df = df[[cols[-2]] + [cols[-1]] + cols[0:24]]\n",
    "df = df.fillna(0)\n",
    "df2 = df.iloc[:, 2:26].astype(int)\n",
    "df = df[[cols[-2]] + [cols[-1]]]\n",
    "df = df.join(df2)\n",
    "uid = df[['uuid', 'period_end_date']]\n",
    "uid\n",
    "#df.to_csv('PRETTY_TEMP_FILE.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e10a154",
   "metadata": {},
   "source": [
    "# Data preprocessing for single categories (faster if wanted to view single category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b6edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the games categories and reformatting the dataframe\n",
    "df1 = pd.read_csv('APP_SUM_DATA.csv')\n",
    "df1 = df1.drop(['TOOLS'], axis=1)\n",
    "df1['GAMES'] = df1.iloc[:, 9:24].sum(axis=1)\n",
    "df1 = df1.drop(df1.iloc[:, 9:24], axis=1)\n",
    "df1 = df1.iloc[:, 0:8].join(df1['GAMES']).join(df1.iloc[:, 8:36])\n",
    "df1.iloc[:, 20:26]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba17ad2",
   "metadata": {},
   "source": [
    "# K-means and self created indicator value for one category (indicator value calculated with dunn_index, entropy and balance values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('DD_clustering_series.csv')\n",
    "df = df.iloc[:, 9:27].join(df.iloc[:, 3:9])\n",
    "\n",
    "\n",
    "k = 1\n",
    "dunn_index_list = []\n",
    "balance_list = []\n",
    "entropy_list = []\n",
    "score_list = []\n",
    "while k < 20: #Clustering from k=1 to k=20\n",
    "\n",
    "\n",
    "    cl_count = k\n",
    "    km = TimeSeriesKMeans(n_clusters=cl_count, metric=\"dtw\") #K-means algorithm with dynamic time warping\n",
    "\n",
    "    labels = km.fit_predict(df) #Giving the cluster lables to timeseries data\n",
    "\n",
    "    df['cluster%s' % k] = labels\n",
    "\n",
    "    x = 0\n",
    "    cluster_list = []\n",
    "    while x < k:\n",
    "        clusters = df.loc[df['cluster%s' % k].astype(int) == x]\n",
    "        clusters = clusters.drop(['cluster%s' % k], axis=1)\n",
    "        cluster_list.append(clusters.values)\n",
    "        x += 1\n",
    "\n",
    "\n",
    "\n",
    "    dunn_index = base.dunn(cluster_list)\n",
    "    print(dunn_index)\n",
    "    dunn_index_list.append(dunn_index)\n",
    "    \n",
    "    pd_series = pd.Series(labels)\n",
    "    j = pd_series.value_counts()\n",
    "    ent = entropy(j)\n",
    "    entropy_list.append(ent)\n",
    "    balance = (max(j) - min(j))/ max(j)\n",
    "    balance_list.append(balance)\n",
    "    \n",
    "    k +=1\n",
    "\n",
    "print(dunn_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bae76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new dataframe that has the entropy, balance and dunn_index to calculate\n",
    "#the indicator value\n",
    "scores = pd.DataFrame([dunn_index_list, entropy_list, balance_list, score_list]) \n",
    "scores = scores.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3655e949",
   "metadata": {},
   "source": [
    "# Calculating indicator value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eef91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SCORES_LIST.csv')\n",
    "df3 = preprocessing.normalize([df['dunn_index'], 1-df['entropy'], df['balance']] )\n",
    "df['d_normalised'] = df3[0]\n",
    "df['1 - e_normalised'] = df3[1]\n",
    "df['b_normalised'] = df3[2]\n",
    "df['score'] = 0.4*df['d_normalised']+0.4*df['1 - e_normalised']+0.2*df['b_normalised'] #Final indicator value's list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d08fb0",
   "metadata": {},
   "source": [
    "# Drawing the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98200f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_count = 5\n",
    "\n",
    "plot_count = math.ceil(math.sqrt(cl_count))\n",
    "fig, axs = plt.subplots(plot_count,plot_count,figsize=(25,25))\n",
    "fig.suptitle('Clusters')\n",
    "row_i=0\n",
    "column_j=0\n",
    "cl_number = 0\n",
    "\n",
    "\n",
    "for label in set(labels):\n",
    "    cluster = []\n",
    "    for i in range(len(labels)):\n",
    "            if(labels[i]==label):\n",
    "                axs[row_i, column_j].plot(df.iloc[i], c=\"gray\",alpha=0.4)\n",
    "                cluster.append(df.iloc[i])\n",
    "                \n",
    "    if len(cluster) > 0:\n",
    "        axs[row_i, column_j].plot(dtw_barycenter_averaging(np.vstack(cluster)),c=\"red\")\n",
    "    axs[row_i, column_j].set_title(\"Cluster \"+str(cl_number))\n",
    "    cl_number += 1 \n",
    "    column_j+=1\n",
    "    if column_j%plot_count == 0:\n",
    "        row_i+=1\n",
    "        column_j=0\n",
    "\n",
    "#plt.savefig('PIC_NAME.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48640fa0",
   "metadata": {},
   "source": [
    "# Example of clustering format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd339543",
   "metadata": {},
   "source": [
    "![alt text](Clustering_K9.png \"Example of cluster format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb6d9e9",
   "metadata": {},
   "source": [
    "# Script for boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8849722",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(10, 7))\n",
    " \n",
    "# Creating axes instance\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.set_xticklabels(['Cluster_0', 'Cluster_1',\n",
    "                    'Cluster_2', 'Cluster_3', 'Cluster_4', 'Cluster_5', 'Cluster_6'])\n",
    " \n",
    "# Creating plot\n",
    "bp = ax.boxplot(cl)\n",
    " \n",
    "# show plot\n",
    "#plt.savefig('BOX_PLOT.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229c588e",
   "metadata": {},
   "source": [
    "# Example for the boxplot format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2cd920",
   "metadata": {},
   "source": [
    "![alt text](DD_box_6_k6.png \"Example of boxplot format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606af0c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
